# **CURSO : DATA SCIENCE FOUNDATIONS ( Fundamentos de Ciência de Dados )** #

## Objetivos ##
   - A day in the life of a Data Science person
   - What tools do data science people use?
   - R x Python 

## Topic : _A day in the life of a Data Science person_ ##
 I've built a recommendation engine before as part of a large organization and worked through all types of engineers and accounted for different parts of the problem. It's one of the one's I'm most happy with because ultimately I came up with the very simple solution that was easy to understand from all levels, from the executives to the engineers and developers. Ultimately it was just as efficient as something really complex that I could have spent a lot more time on.
 Back in the university we have a problem that we wanted to predict algal bloom. This algae bloom could cause rising toxicity of the water and it could cause problems to the water treatment company. We couldn't predict it with our chemical engineering background so we used artificial neural-networks to predict when this bloom will occur. So the water treatment companies could better handle this problem. In Toronto the public transit is operated by Toronto Transit Commission. We call them TTC.
 It's one of the largest transit authorities in the region in North America. And one day they contacted me and said, 'we have a problem'. And I said okay, what's the problem. They said, 'well we have complaints data and we would like to analyze it and we need your help'. I said fine I'll be very happy to help. So I said how many complaints do you have? They said, 'a few'. I said how many? 'Maybe half a million'.
 I said well let's start working with it. So I got the data and I started analyzing it. So basically they have done a great job at keeping the data, some data in tabular format other was unstructured data. And in that case tabular data was when the complaint arrived, who received it, what was the type of the complaint, was it resolved, whose fault was it. And the unstructured part of it was the exchange of emails and faxes. So imagine looking at half a million exchanges of emails and trying to get some answer from it.
 So I started working with it and the first thing I wanted to know is why would people complain and is there a pattern. Are there some days where there are
 more complaints than others? And I looked at the data and I analyzed it in all different formats and I couldn't find what the impetus for complaints being higher on a certain day and lower on others. And it continued for maybe a month of so and then one day I was getting off the bus in Toronto and I was still thinking about it and I stepped out without looking on the ground and I stepped into a puddle, puddle of water.
 And now I was sort of ankle deep into water and it was just one foot wet and the other dry and I was extremely annoyed. And I was walking back and then it hit me and I said well wait a second. Today it rained unexpectedly and I wasn't prepared for it. That's why I'm wet and I wasn't looking for it. What if there's a relationship between extreme weather and the type of complaints TTC receives? So I went to the Environment Canada's website and I got data on rain and precipitation, wind and the like.
 And there I found something very interesting. The ten most excessive days for complaints, the ten days were people complain the most were the days when the weather was bad. It was unexpected rain, an extreme drop in temperature, too much snow, a very windy day. So I went back to the TTC's executives and I said, I've got good news and bad news. I said, the good news is I know why people would complain excessively on certain days. I know the reason for it. The bad news is there's nothing you can do about it.

### _Description : A day in the life of a Data Science person_ ###
 Este conteúdo aborda as ações cotidianas de um profissional de análise de dados, que geralmente é responsável por lidar com o tratamento de dados para resolver situações que exigem específica solução. Como citado anteriormente, os profissionais são encarregados para oferecer suporte às organizações, afim de auxiliar o entendimento de informações obtida por meio de coleta de dados, exigindo aplicação de conhecimento técnico e prático sobre a área de atuação.

------------------------------------------------------------------------------------

## Topic : _R vs Python_ ##
 As I have an engineering background, I started programming with C, then I went to Matlab, and eventually to Python. I usually use Matlab, C, and C++,
 but for data science I use Python. 
 Between R and Python?. I choose R. I'm an R evangelist. I was at the useR Conference last year and I think it's got one of the best communities, I'm also very fond of SQL and I think people don't spend enough time appreciating it in its various incarnations.
 I primarily work with R and Stata. I do not work a lot with big data so for the kind of data sets I have, there are a few million observations, even the hundreds of millions of observations then I can work with with the existing Stata and R and SPSS, I don't have a problem with it, but as I said, if I were to work with large data sets, I would use different tools.
 My preferred tools are the three: R, Stata, and SPSS. I also work with spacial data a lot so these are data sets which have a geographical component to it, so imagine 40 million Californians and 40 million people, some of them in California, some of them in the neighboring states, and what if I know the exact home address of each and everyone of them and where they work.
 And that would be an amazing GIS, spacial geographic information systems database. So I work with those as well and my tool that I use is called Maptitude and MapInfo, these are the two I use the most. 

### _Description : R x Python_ ###
 O uso de ferramentas otimiza o processo de identificação, coleta e manipulação de dados. Normalmente, linguagens de progrmação como R e Python podem ser utilizadas para viabilizar a interpretação e análise de informações entre diferentes tipos de dados, sob larga escala, também podendo ser integrado com informações armazenadas em banco de dados ( SQL ).

------------------------------------------------------------------------------------

## Topic : _Data Science Tools and Technology_ ##
 I really enjoy regression. I'd say regression was maybe one of the first concepts that really helped me understand data, so I enjoy regression. I really like data visualization. I think it's a key element for people to get across their message to people that don't understand that well what data science is.
 Artificial neural networks. I'm really passionate about neural networks because we have a lot to learn from nature so when we are trying to mimic our brain, I think that we can do some applications with this behavior, this biological behavior in algorithms. Data visualization with R, I love to do this. Nearest neighbor, it's the simplest, but it just gets the best results so many more times, than some overblown, overworked algorithm that's just as likely to over fit as it is to make a good fit.
 So, structured data is more like tabular data, things that you're familiar with in Microsoft Excel format, you've got rows and columns, and that's called structured data.Unstructured data is basically data that is coming from mostly from web, where it's not tabular. It is not in rows and columns, it's text. Sometimes it's video and audio. You would have to deploy more sophisticated algorithms to extract data.
 In fact, a lot of times, we take unstructured data and spend a great deal of time and effort to get some structure out of it and then analyze it. If you have something which just fits nicely into tables and columns and rows go ahead. That's your structured data, but if you see if it's a weblog, or if you're trying to get information out of webpages, and you've got a gazillion webpages, that's unstructured data, that would require a little bit more effort to get information out of it.
 Machine learning is basically a set of these advanced tools people use to find answers. I'm not a big fan of machine learning, and I'll give you my bias right now. Imagine there's an island and there are about 45,000 people who live on that island. It's cut off from the rest of the world, nobody can swim into the island, or swim out of the island.
 Now imagine that island had a murder, and you're the detective who's been tasked with finding who the culprit is. Now, there's various approaches you can take. One approach is you say, well, whoever killed this person is on this island. So there are 45,000 people and there are 45,000 suspects.
 I'm going to go one by one asking each person until I find the suspect, right. That's machine learning, because you have no other reason, no other assumptions, no other hypothesis, no other feeling. You say, I don't know anything. I'm just going to throw everything into my model and see who the culprit is. Sometimes you get to the culprit, sometimes you don't,
 but it would take time.
 Machine learning is basically saying when you do not have many assumptions about your data, and you're short of knowing a lot about your data, you just throw everything into this model, and see what comes out of it. It's more of a black box approach. I know that a large number of professionals live by it. I, on the other hand, like to look at data with my own preconceived notions, because it is said, a data scientist is someone who is very judgmental.
 That person, a data scientist is one who has an opinion about data. Who has an opinion about the phenomena they're learning, or they're investigating. They cannot simply believe
 that I'm going to have a kitchen sink approach, I'm going to dump everything in the model. Machine learning is basically saying, dump everything, see what comes out of it. There are thousands of books written on regression, and millions of lectures delivered on regression. And I always feel that they don't do a good job of explaining regression, because they get into data and models and statistical distributions.
 Let's forget about it, let me explain regression in the simplest possible terms. If you have ever taken a cab ride, a taxi ride, you understand regression. Here's how it works. The moment you sit in a cab ride, in a cab, you see that there's a fixed amount there, it says 2 dollars 50 cents, $2.50; You rather that the cab moves or you get off, this is what you owe to the driver, the moment you step into a cab. That's a constant, you have to pay that amount, if you have stepped into a cab. Then as it starts moving, for every meter or 100 meters, the fare increases by a certain amount.
 So, there's a fraction, there's a relationship between distance and the amount you would pay, above and beyond that constant. If you're not moving, and you're stuck in traffic, then every additional minute, you have to pay more. As the minutes increase, your fare increases, as the distance increases, your fare increases, and while all this is happening,  you've already paid a base fare, which is the constant.
 This is what regression is. Regression tells you what the base fare is and what is the relationship between time and the fare you have paid and the distance you have traveled and the fare you have paid. Because in the absence of knowing those relationships, and just knowing how much people traveled for, and how much they paid, regression allows you to compute that constant that you didn't know it was 2.50, and it would compute the relationship between the fare and the distance, and the fare and the time. That's a regression.


### _Description : Data Science Tools and Technology_ ###
 O tópico valoriza a regressão como base do entendimento de dados e a visualização como ferramenta essencial de comunicação. Defende o uso de algoritmos simples, como KNN, que superam os modelos complexos e inflados. Além disso, existe a diferença entre os dados estruturados ( tabelas e colunas ) e não estruturados ( outros arquivos ).
 Resumidamente, a regressão é explicada de forma brilhante pela analogia de uma corrida de taxi: onde um valor fixo inicial ( constante ) e valores que variam conforme a distância e o tempo. A regressão é uma ferramenta que permite calcular esses valroes ocultos observando apenas o histórico de viagens

## Material - **Regressão** ##
 Este capítulo explora a "ferramenta de trabalho" fundamental da análise estatística, desde a origem até o presente momento.

   - Material : [Regressão - BigDataUniversity](Regression%20-%20BigDataUniversity.pdf)

   > **Origem Histórica** : A técnica foi formalizada por _Francis Galton_ em 1886, ao estudar por que pais de alta estatura não tinham filhos, necessariamente, mais altos que eles ( regressão sob medida ).

   > **Uso Ubíquo** : Atualmente, modelos de regressão são essenciais na medicina e nos negócios

   > **Departamento de Conclusões Óbvias** : O autor usa uma anedota pessoa sobre sua tese de mestado para explicar que a regressão vai além do óbvio.

   > **Quantificação de Impacto** : A regressão quantifica quanto cada variável impacta em seus respectivos quisitos. 

-------------------------------------------------------------------------------

### _Review Questions_ ###
 
 1. _What is structured data?_
    > Resposta : **Data that can be stored in a database or some tabular form**

 2. _What does the following formula represent: Base fair + Time x (Time in cab)_
    > Resposta : **The possible formula used in regression analysis to determine the cost of a cab ride**

 3. _In the reading "**Getting Started with Data Science**", what is the example of a question that can be put on a Regression Analysis?_
    > Resposta : **What is the impact of lot size on housing price?**